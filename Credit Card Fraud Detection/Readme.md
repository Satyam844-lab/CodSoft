<center>üí≥ Credit Card Fraud Detection Project</center>
<hr> <h2>Project Overview</h2> <p> This project uses machine learning to detect fraudulent transactions in credit card data. It demonstrates the full pipeline: data cleaning, feature engineering, model building (Logistic Regression/Random Forest), evaluation, and interactive prediction on new transactions. The solution is designed for high-impact, real-world use cases such as banking, e-commerce, and fintech. </p> <hr> <h2>üìÇ Dataset</h2> <ul> <li><b>Source:</b> <a href="https://www.kaggle.com/datasets/kartik2112/fraud-detection">Kaggle - Credit Card Transactions Fraud Detection</a></li> <li><b>Size:</b> 500,000+ transactions</li> <li><b>Fraud Cases:</b> <1% of all transactions (<code>is_fraud</code> column is the target)</li> <li><b>Features:</b> Categorical, geographic, and temporal data (amount, merchant category, location, time, etc.)</li> </ul> <hr> <h2>üõ†Ô∏è Workflow Overview</h2> <ol> <li><b>Load & Explore Data</b> <ul> <li>Initial data check (shape, head, missing values)</li> <li>Visualize class imbalance (fraud vs. non-fraud)</li> </ul> </li> <li><b>Preprocessing</b> <ul> <li>Drop unique IDs, names, and purely textual columns</li> <li>Extract temporal features (hour, day of week)</li> <li>One-hot encode categorical variables</li> <li>Scale numeric features</li> </ul> </li> <li><b>Modeling</b> <ul> <li>Split dataset (stratified train/test split)</li> <li>Train Logistic Regression or Random Forest (class-weighted for imbalance)</li> </ul> </li> <li><b>Evaluation</b> <ul> <li>Confusion matrix, classification report, ROC-AUC score</li> <li><i>Recall is prioritized to catch as many frauds as possible</i></li> </ul> </li> <li><b>Interactive Prediction</b> <ul> <li>User-friendly input function to classify new transactions</li> </ul> </li> </ol> <hr> <h2>üìà Example Results</h2> <pre> Confusion Matrix: [[100173 10542] [ 27 402]] Classification Report: precision recall f1-score support 0 1.00 0.90 0.95 110715 1 0.04 0.94 0.07 429 accuracy 0.90 111144 macro avg 0.52 0.92 0.51 111144 weighted avg 1.00 0.90 0.95 111144 ROC-AUC Score: 0.9787 </pre> <ul> <li>High recall (94%) for fraud cases (almost all frauds detected)</li> <li>Lower precision‚Äîmany false alarms, common in real-world fraud screening (can be tuned further)</li> <li>Strong ROC-AUC means good separation between fraud and normal transactions</li> </ul> <hr> <h2>üíª How to Run This Project</h2> <ol> <li>Clone the repository and install dependencies:</li> <pre> pip install pandas numpy matplotlib seaborn scikit-learn </pre> <li>Download <b>fraudTest.csv</b> from <a href="https://www.kaggle.com/datasets/kartik2112/fraud-detection">Kaggle</a> and place it in your project folder.</li> <li>Run the script in your Python environment (Jupyter Notebook or any IDE).</li> <li> To test prediction on new data: <ul> <li>Uncomment the <code>user_transaction_prediction()</code> line at the end of the script.</li> <li>Run and enter transaction details as prompted.</li> </ul> </li> </ol> <hr> <h2>üìù Key Learnings & Next Steps</h2> <ul> <li>How to handle imbalanced datasets using stratified splitting and class weighting</li> <li>Model evaluation using confusion matrix, recall, precision, F1, ROC-AUC</li> <li>Building robust user input pipelines for real-time ML inference</li> <li>You can further improve by: <ul> <li>Tuning classification thresholds for desired precision/recall balance</li> <li>Trying ensemble models (Random Forest, XGBoost)</li> <li>Adding SMOTE or undersampling for better class balance</li> <li>Deploying as a web app with Streamlit or Flask</li> </ul> </li> </ul> <hr> <h2>üôã
